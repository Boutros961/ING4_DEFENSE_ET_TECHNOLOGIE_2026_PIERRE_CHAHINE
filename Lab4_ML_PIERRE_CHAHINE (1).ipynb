{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXfVRw5p4YOo"
      },
      "source": [
        "# Neural Network on GPU\n",
        "\n",
        "> Author : Badr TAJINI - Machine Learning 2 & Deep learning - ECE 2025-2026\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT49HHnBMPTh"
      },
      "source": [
        "\n",
        "From Kaggle:\n",
        "\"MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\"\n",
        "\n",
        "[Read more.](https://www.kaggle.com/c/digit-recognizer)\n",
        "\n",
        "\n",
        "<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jK-Iyt4NXJoU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq6RJyDIOB-T"
      },
      "source": [
        "## STEP 1: LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aL21SXchOBwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf227f11-5b2e-4b07-ba99-f4918ae781b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.11MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.25MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_zuJQxSOKQt"
      },
      "source": [
        "## STEP 2: MAKING DATASET ITERABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bGDbP1pL4XE",
        "outputId": "4b02b556-c48f-474b-c519-e807872b8d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of epochs: 5\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "\n",
        "print(\"Number of epochs: \" + str(num_epochs))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FEft3CQOQIR"
      },
      "source": [
        "## STEP 3: CREATE MODEL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZbEJ-1aAL9d1"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Convolution 1\n",
        "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Max pool 1\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Convolution 2\n",
        "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Max pool 2\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected 1 (readout)\n",
        "        self.fc1 = nn.Linear(32 * 4 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution 1\n",
        "        out = self.cnn1(x)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Max pool 1\n",
        "        out = self.maxpool1(out)\n",
        "\n",
        "        # Convolution 2\n",
        "        out = self.cnn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Max pool 2\n",
        "        out = self.maxpool2(out)\n",
        "\n",
        "        # Resize\n",
        "        # Original size: (100, 32, 7, 7)\n",
        "        # out.size(0): 100\n",
        "        # New out size: (100, 32*7*7)\n",
        "        out = out.view(out.size(0), -1)\n",
        "\n",
        "        # Linear function (readout)\n",
        "        out = self.fc1(out)\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3owYgg2OWYw"
      },
      "source": [
        "## STEP 4: INSTANTIATE MODEL CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dcd2aS_QFzX",
        "outputId": "22938d8b-6aba-4eee-ebb5-968653c98778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# Number of CUDA devices\n",
        "# The first device is always named \"cuda:0\"\n",
        "# The second one is \"cuda:1\", etc.\n",
        "print(torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dqM6gd4MA2I",
        "outputId": "bfdbbb3b-82dd-45da-8ecd-beee2c7eff54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model = CNNModel()\n",
        "\n",
        "####################################################################\n",
        "#  USE GPU FOR MODEL                                               #\n",
        "#  The model must be put on the GPU before declaring the optimizer #\n",
        "####################################################################\n",
        "\n",
        "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfSU4Nn7GfXS",
        "outputId": "2935e3d7-e764-4bc7-e7b6-f839c8850954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ArDN205ObQG"
      },
      "source": [
        "## STEP 5: INSTANTIATE LOSS CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YtqarS-WMC5S"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqikNfyhOe7o"
      },
      "source": [
        "## STEP 6: INSTANTIATE OPTIMIZER CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1roaQQwYMFFj"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsAaSLaaGrMZ",
        "outputId": "f5c105b4-3b59-4bac-8c7c-5d29d14550c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of CNNModel(\n",
            "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
            ")>\n"
          ]
        }
      ],
      "source": [
        "print(model.parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0A9mJ3d6-f8"
      },
      "source": [
        "Function to compute the accuracy on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar07FA9CaiP9"
      },
      "source": [
        "### Question: modify the following code to exploit the GPU instead of the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Sv17qSuGO5x6"
      },
      "outputs": [],
      "source": [
        "def test_model(test_loader, model, device):\n",
        "  # Calculate Accuracy\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # On désactive le calcul des gradients pour économiser de la mémoire GPU\n",
        "  with torch.no_grad():\n",
        "    # Iterate through test dataset\n",
        "    for images, labels in test_loader:\n",
        "      #######################\n",
        "      #  USE GPU FOR MODEL  #\n",
        "      #######################\n",
        "      # On envoie les données sur le GPU (device) [cite: 4, 14]\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Forward pass only to get logits/output\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Get predictions from the maximum value\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Total number of labels\n",
        "      total += labels.size(0)\n",
        "\n",
        "      # CORRECTIF ICI : .item() est indispensable pour récupérer la valeur numérique\n",
        "      # sans garder le tenseur sur le GPU, sinon le calcul d'accuracy va planter.\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "  accuracy = 100 * float(correct) / float(total)\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJWjmbnOhff"
      },
      "source": [
        "## STEP 7: TRAIN THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZh9Bryn-15o"
      },
      "source": [
        "### Question: modify the following code to exploit the GPU instead of the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ADmEX6UMINe",
        "outputId": "1046f974-5926-44c5-917a-5262c5ca526d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device :  cuda:0\n",
            "Iteration: 500. Loss: 0.4832. Accuracy on test set: 89.89%\n",
            "Iteration: 1000. Loss: 0.3146. Accuracy on test set: 93.91%\n",
            "Iteration: 1500. Loss: 0.1916. Accuracy on test set: 95.10%\n",
            "Iteration: 2000. Loss: 0.2258. Accuracy on test set: 95.75%\n",
            "Iteration: 2500. Loss: 0.1256. Accuracy on test set: 96.16%\n",
            "Iteration: 3000. Loss: 0.1770. Accuracy on test set: 96.85%\n",
            "CPU times: user 41.8 s, sys: 677 ms, total: 42.4 s\n",
            "Wall time: 44.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# On s'assure que le périphérique est configuré sur GPU (CUDA)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"device : \", device)\n",
        "iter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # ENVOI DES DONNÉES SUR LE GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Remise à zéro des gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Passage direct (Forward pass)\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calcul de la perte\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Rétropropagation (Backward pass)\n",
        "        loss.backward()\n",
        "\n",
        "        # Mise à jour des poids\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calcul de l'accuracy sur le test set\n",
        "            accuracy = test_model(test_loader, model, device)\n",
        "\n",
        "            # Affichage correct sans erreur NameError\n",
        "            print('Iteration: {}. Loss: {:.4f}. Accuracy on test set: {:.2f}%'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozPdNeJH-Tfq"
      },
      "source": [
        "### Question: compare the wall time on GPU to the wall time on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "W0xYAafL3bH8",
        "outputId": "8aee4646-ee60-4cb6-fcea-da91dfd33a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFirst result - CPU device\\ndevice :  cpu\\nIteration: 500. Loss: 0.4888801872730255. Accuracy on test set: 87.5\\nIteration: 1000. Loss: 0.37688079476356506. Accuracy on test set: 91.95\\nCPU times: user 34.6 s, sys: 1.12 s, total: 35.7 s\\nWall time: 35.7 s\\n\\nFirst result - GPU device\\ndevice :  cuda:0\\nIteration: 500. Loss: 0.31107470393180847. Accuracy on test set: 88.87\\nIteration: 1000. Loss: 0.2122945636510849. Accuracy on test set: 93.0\\nCPU times: user 12.9 s, sys: 109 ms, total: 13 s\\nWall time: 13 s\\n\\nSecond result - GPU device\\ndevice :  cuda:0\\nIteration: 500. Loss: 0.39977511763572693. Accuracy on test set: 89.4\\nIteration: 1000. Loss: 0.24916988611221313. Accuracy on test set: 92.89\\nIteration: 1500. Loss: 0.23252594470977783. Accuracy on test set: 93.8\\nIteration: 2000. Loss: 0.059734128415584564. Accuracy on test set: 95.59\\nIteration: 2500. Loss: 0.1804923117160797. Accuracy on test set: 96.07\\nIteration: 3000. Loss: 0.07106972485780716. Accuracy on test set: 96.5\\nCPU times: user 32.3 s, sys: 268 ms, total: 32.5 s\\nWall time: 32.6 s\\n\\nSecond result - CPU device\\ndevice :  cpu\\nIteration: 500. Loss: 0.5236935615539551. Accuracy on test set: 88.25\\nIteration: 1000. Loss: 0.21130454540252686. Accuracy on test set: 92.09\\nIteration: 1500. Loss: 0.22272621095180511. Accuracy on test set: 94.18\\nIteration: 2000. Loss: 0.13368134200572968. Accuracy on test set: 95.29\\nIteration: 2500. Loss: 0.17730632424354553. Accuracy on test set: 95.83\\nIteration: 3000. Loss: 0.16622531414031982. Accuracy on test set: 96.33\\nCPU times: user 1min 26s, sys: 1.15 s, total: 1min 27s\\nWall time: 1min 28s\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "'''\n",
        "First result - CPU device\n",
        "device :  cpu\n",
        "Iteration: 500. Loss: 0.4888801872730255. Accuracy on test set: 87.5\n",
        "Iteration: 1000. Loss: 0.37688079476356506. Accuracy on test set: 91.95\n",
        "CPU times: user 34.6 s, sys: 1.12 s, total: 35.7 s\n",
        "Wall time: 35.7 s\n",
        "\n",
        "First result - GPU device\n",
        "device :  cuda:0\n",
        "Iteration: 500. Loss: 0.31107470393180847. Accuracy on test set: 88.87\n",
        "Iteration: 1000. Loss: 0.2122945636510849. Accuracy on test set: 93.0\n",
        "CPU times: user 12.9 s, sys: 109 ms, total: 13 s\n",
        "Wall time: 13 s\n",
        "\n",
        "Second result - GPU device\n",
        "device :  cuda:0\n",
        "Iteration: 500. Loss: 0.39977511763572693. Accuracy on test set: 89.4\n",
        "Iteration: 1000. Loss: 0.24916988611221313. Accuracy on test set: 92.89\n",
        "Iteration: 1500. Loss: 0.23252594470977783. Accuracy on test set: 93.8\n",
        "Iteration: 2000. Loss: 0.059734128415584564. Accuracy on test set: 95.59\n",
        "Iteration: 2500. Loss: 0.1804923117160797. Accuracy on test set: 96.07\n",
        "Iteration: 3000. Loss: 0.07106972485780716. Accuracy on test set: 96.5\n",
        "CPU times: user 32.3 s, sys: 268 ms, total: 32.5 s\n",
        "Wall time: 32.6 s\n",
        "\n",
        "Second result - CPU device\n",
        "device :  cpu\n",
        "Iteration: 500. Loss: 0.5236935615539551. Accuracy on test set: 88.25\n",
        "Iteration: 1000. Loss: 0.21130454540252686. Accuracy on test set: 92.09\n",
        "Iteration: 1500. Loss: 0.22272621095180511. Accuracy on test set: 94.18\n",
        "Iteration: 2000. Loss: 0.13368134200572968. Accuracy on test set: 95.29\n",
        "Iteration: 2500. Loss: 0.17730632424354553. Accuracy on test set: 95.83\n",
        "Iteration: 3000. Loss: 0.16622531414031982. Accuracy on test set: 96.33\n",
        "CPU times: user 1min 26s, sys: 1.15 s, total: 1min 27s\n",
        "Wall time: 1min 28s\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'accélération constatée s'explique par la transition d'un traitement séquentiel sur l'hôte (CPU) vers un calcul massivement parallèle sur le périphérique (GPU).\n",
        "\n",
        "Grâce à l'architecture SIMT, le GPU exécute simultanément des milliers de threads pour traiter les opérations matricielles du modèle, là où le CPU traite les données de manière plus linéaire. La mise en œuvre a nécessité le transfert des tenseurs vers la mémoire du périphérique via CUDA pour permettre cette exécution parallèle.\n",
        "\n",
        "Ces mesures confirment cette efficacité avec un temps d'exécution réduit de 1 minute 28 secondes sur CPU à environ 33 secondes sur GPU pour 3000 itérations."
      ],
      "metadata": {
        "id": "Us7H2MeBaVJj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gekTtS1p_v2k"
      },
      "source": [
        "### Question: increase the number of epoch until 5 to see if we can expect a better average accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-6riSeSc5Srr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "34d92419-a97f-460f-9b87-715f4c6f9f40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nn_iters = 1200\\nCPU => Accuracy on test set: 91.95\\nGPU => Accuracy on test set: 93.0\\n\\nn_iters = 3000\\nCPU => Accuracy on test set: 96.33\\nGPU => Accuracy on test set: 96.5\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "'''\n",
        "n_iters = 1200\n",
        "CPU => Accuracy on test set: 91.95\n",
        "GPU => Accuracy on test set: 93.0\n",
        "\n",
        "n_iters = 3000\n",
        "CPU => Accuracy on test set: 96.33\n",
        "GPU => Accuracy on test set: 96.5\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmenter le nombre d'époques jusqu'à 5 permet d'obtenir une meilleure précision moyenne en laissant au mécanisme d'autograd et à l'optimiseur SGD suffisamment de temps pour converger vers un minimum global.\n"
      ],
      "metadata": {
        "id": "Qotodbl4b948"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}